# -*- coding: utf-8 -*-
"""TA7_WHISPER_IVANFALCONMONZON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L_lvH1uuGAkEU3VgJ-FdacW1fIboKe58

# **IVAN FALCON MONZON**

**TAREA 7 (24-25) WHISPER (Hugging Face)**

# **0. OBJETIVO**

El propósito de esta tarea es que con el modelo Whisper de OpenAl, disponible en Hugging Face, transcribir el audio de una canción descargada.

# **1. Instalación y configuración del entorno**

Este código instala y configura el entorno necesario para trabajar con modelos de procesamiento de audio. Instala las librerías **transformers, torch, datasets, pydub y accelerate**, que son necesarias para utilizar modelos de secuencia a secuencia para tareas de audio, así como para trabajar con procesamiento de audio en general.

Luego, importa las librerías requeridas, como **AutoModelForSpeechSeq2Seq y AutoProcessor** de la librería transformers para manejar el modelo y el procesamiento de audio, y pydub para la manipulación de archivos de audio.
"""

# IVAN FALCON MONZON
# 1. Instalación y configuración del entorno

# Instalar las librerías necesarias
!pip install transformers torch datasets pydub accelerate

# Importar las librerías necesarias
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
import torch
from pydub import AudioSegment

"""Este código configura el entorno para utilizar el modelo Whisper-large-v3 de OpenAI para tareas de transcripción de audio.

Primero, define el dispositivo a utilizar (GPU si está disponible, de lo contrario, usa la CPU) y ajusta el tipo de dato en función del dispositivo.


Luego, carga el modelo preentrenado Whisper-large-v3 con optimización de memoria y asegura el uso de tensores seguros. El modelo se mueve al dispositivo seleccionado (GPU o CPU).

También se carga el procesador del modelo para la transcripción de audio y se configura un pipeline de reconocimiento automático de voz (automatic-speech-recognition) que utiliza el modelo y el procesador para convertir el audio en texto.
"""

# IVAN FALCON MONZON
# 1.1 Instalación y configuración del entorno

# Definir el dispositivo a utilizar (GPU si está disponible, de lo contrario CPU)
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

# Especificar el modelo Whisper a utilizar
model_id = "openai/whisper-large-v3"

# Cargar el modelo preentrenado con optimización de memoria y formato seguro
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
)

# Mover el modelo al dispositivo seleccionado
model.to(device)

# Cargar el procesador del modelo para la transcripción
processor = AutoProcessor.from_pretrained(model_id)

# Crear un pipeline de reconocimiento automático de voz
pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
)

"""# **2. Selección y descarga del audio**

Este código descarga un archivo de audio en formato MP3 desde un repositorio de GitHub y lo carga utilizando la librería pydub para su manipulación.


El archivo se convierte a una frecuencia de muestreo de 16 kHz y se convierte a mono (una sola pista de audio).

Luego, se define la duración de cada segmento de audio (30 segundos) y se calcula cuántos segmentos se necesitan para cubrir la duración total del archivo.

Finalmente, el audio se divide en segmentos de 30 segundos y se exportan en formato WAV.
"""

# IVAN FALCON MONZON
# 2. Selección y descarga del audio

# Descargar el archivo de audio desde GitHub
!wget -O musica.mp3 "https://raw.githubusercontent.com/IvanFalconMonzon/TA7_WHISPER_IVANFALCONMONZON/main/musica.mp3"

# Cargar la librería para manipulación de audio
from pydub import AudioSegment

# Cargar el archivo MP3 descargado y convertirlo a 16kHz y mono (una sola pista de audio)
audio = AudioSegment.from_file("musica.mp3").set_frame_rate(16000).set_channels(1)

# Definir la duración de cada segmento en milisegundos (30 segundos)
segment_duration = 30 * 1000

# Calcular el número de segmentos necesarios
num_segments = len(audio) // segment_duration + 1

# Dividir y exportar los segmentos en formato WAV
for i in range(num_segments):
    segment = audio[i * segment_duration:(i + 1) * segment_duration]
    segment.export(f"segment_{i}.wav", format="wav")

"""# **3. Uso del modelo Whisper**

Este código utiliza el modelo Whisper para transcribir cada segmento de audio previamente dividido.

Primero, se crea una lista vacía para almacenar las transcripciones de cada segmento. Luego, para cada segmento de audio (en formato WAV), se procesa utilizando el pipeline de transcripción creado anteriormente, especificando que el idioma es inglés.

La transcripción de cada segmento se guarda en la lista transcriptions.

Finalmente, todas las transcripciones se unen en un solo texto, formando la transcripción completa del archivo de audio.
"""

# IVAN FALCON MONZON
# 3. Uso del modelo Whisper

# Lista para almacenar las transcripciones de cada segmento
transcriptions = []

# Procesar cada segmento de audio con Whisper
for i in range(num_segments):
    result = pipe(f"segment_{i}.wav", return_timestamps=False, generate_kwargs={"language": "english"})
    transcriptions.append(result["text"])  # Guardar la transcripción del segmento

# Unir todas las transcripciones en un solo texto
full_transcription = " ".join(transcriptions)

"""# **4. RESULTADO FINAL**"""

# IVAN FALCON MONZON
# 4. Resultado final
print("Transcripción completa:", full_transcription)

"""# **5. CONCLUSIONES**

- Precisión alta: El modelo transcribe correctamente la letra de la canción sin
errores notables.

- Calidad de audio suficiente: El audio procesado a 16 kHz y mono es adecuado para la transcripción.

- Buen desempeño del modelo: Whisper transcribe de forma efectiva en inglés, incluso con la música de fondo.

# **6. REPOSITORIO**

GITHUB: https://github.com/IvanFalconMonzon/TA7_WHISPER_IVANFALCONMONZON.git
"""